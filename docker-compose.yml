version: '3.8'

name: de2025_etl_project

x-postgresql-connection-env: &pg-connect
  POSTGRESQL_APP_HOST: ${POSTGRESQL_APP_HOST}
  POSTGRESQL_APP_DB: ${POSTGRESQL_APP_DB}
  POSTGRESQL_APP_SCHEMA: ${POSTGRESQL_APP_SCHEMA}
  POSTGRESQL_APP_USER: ${POSTGRESQL_APP_USER}
  POSTGRESQL_APP_PASSWORD: ${POSTGRESQL_APP_PASSWORD}

x-airflow-common-env: &airflow-common-env
  AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
  AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
  AIRFLOW__CORE__DAG_CONCURRENCY: ${AIRFLOW__CORE__DAG_CONCURRENCY}
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
  AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: ${AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK}
  AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
  AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
  AIRFLOW_UID: ${AIRFLOW_UID}
  AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_WWW_USER_USERNAME}
  AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_WWW_USER_PASSWORD}

services:
  postgres:
    build: services/postgres
    container_name: postgres
    environment:
      <<: *pg-connect
      POSTGRES_PASSWORD: ${POSTGRESQL_ROOT_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    network_mode: "bridge"

  mongo:
    build: ./services/mongo
    container_name: mongo
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      MONGO_DB: ${MONGO_DB}
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
      - ./config/mongo:/docker-entrypoint-initdb.d
    network_mode: "bridge"

  airflow-init:
    build: services/airflow/init
    container_name: airflow-init
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      <<: [*airflow-common-env, *pg-connect]
    volumes:
      - ./python-scripts/airflow/dags:/opt/airflow/dags
      - ./python-scripts/airflow/scripts:/opt/airflow/scripts
      - ./logs/airflow:/opt/airflow/logs
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    network_mode: "bridge"

  airflow-scheduler:
    build: services/airflow/scheduler
    container_name: airflow-scheduler
    environment:
      <<: *airflow-common-env
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./python-scripts/airflow/dags:/opt/airflow/dags
      - ./python-scripts/airflow/scripts:/opt/airflow/scripts
      - ./logs/airflow:/opt/airflow/logs
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
    network_mode: "bridge"

  airflow-webserver:
    build: services/airflow/webserver
    container_name: airflow-webserver
    environment:
      <<: *airflow-common-env
    ports:
      - "8080:8080"
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./python-scripts/airflow/dags:/opt/airflow/dags
      - ./python-scripts/airflow/scripts:/opt/airflow/scripts
      - ./logs/airflow:/opt/airflow/logs
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
    network_mode: "bridge"

  data_generator:
    build: services/data_generator
    container_name: mongo_data_generator
    depends_on:
      - mongo
    environment:
      MONGO_URI: ${MONGO_URI}
    command: ["python", "generate_data.py"]
    network_mode: "bridge"

volumes:
  postgres_data:
  mongo_data:
