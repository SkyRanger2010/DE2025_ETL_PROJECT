# Учебный ETL Проект с Apache Airflow, PostgreSQL и MongoDB

## Описание проекта

Этот проект представляет собой учебный ETL-процесс для репликации данных из MongoDB в PostgreSQL с использованием Apache Airflow. 

### Стек технологий
- **Apache Airflow** – отвечает за управление и автоматизацию выполнения ETL-пайплайнов. Каждый DAG в Airflow реализует процесс извлечения, трансформации и загрузки данных.
- **MongoDB** – источник данных, в котором хранятся сырые данные о пользовательских сессиях, поисковых запросах, истории цен товаров, обращениях в поддержку и других сущностях.
- **PostgreSQL** – хранилище обработанных данных. В него загружаются очищенные, нормализованные и подготовленные для аналитики данные.
- **Генератор данных** – отдельный сервис, который заполняет MongoDB случайными данными, имитируя реальные сущности.
- **Docker** – для контейнеризации всех сервисов и удобного развертывания проекта.
- **Python** – язык программирования для написания ETL-скриптов, а также генерации данных.

Основная цель проекта – научиться настраивать и автоматизировать процессы обработки данных, подготовки их для последующего анализа, а также реализация витрин данных, которые можно использовать для бизнес-аналитики.


## Структура проекта
Проект организован следующим образом:
```plaintext
DE2025_ETL_PROJECT/
├── .env                        # Переменные окружения для настройки всех сервисов
├── docker-compose.yml          # Конфигурация Docker Compose
├── README.md                   # Документация проекта
├── PROJECT_TASK.md             # Задание на учебный проект
│
├── airflow/                    # Сервис Airflow
│   ├── Dockerfile              # Докерфайл Airflow
│   ├── requirements.txt        # Зависимости Airflow
│   ├── config/
│   │   └── airflow.cfg         # Конфигурация Airflow
│   │
│   ├── dags/                   # DAG-файлы для Airflow
│   │   ├── sql/                # SQL запросы для формирования витрин данных
│   │   │   │
│   │   │   ├── support_efficiency_mart.sql        # Запрос на формирование витрины эффективности работы поддержки
│   │   │   └── users_activity_mart.sql            # Запрос на формирование витрины пользовательской активности
│   │   │
│   │   ├── user_sessions_etl.py            # DAG для репликации user_sessions
│   │   ├── event_logs_etl.py               # DAG для репликации event_logs
│   │   ├── search_queries_etl.py           # DAG для репликации search_queries
│   │   ├── user_recommendations_etl.py     # DAG для репликации user_recommendations
│   │   ├── moderation_queue_etl.py         # DAG для репликации moderation_queue
│   │   ├── support_tickets_etl.py          # DAG для репликации support_tickets
│   │   ├── product_price_history_etl.py    # DAG для репликации product_price_history
│   │   ├── mart_users_activity.py          # DAG для построения витрины пользовательской активности
│   │   ├── mart_support_efficiency.py      # DAG для построения витрины эффективности работы поддержки
│   │   ├── users_activity_pipeline.py      # DAG автопайплайна витрины пользовательской активности
│   │   └── support_efficiency_pipeline.py  # DAG автопайплайна витрины эффективности работы поддержки
│   │
│   ├── logs/                   # Логи Airflow
│   └── plugins/                # Плагины Airflow  
│
├── data_generator/             # Сервис генератора данных для MongoDB
│   ├── Dockerfile                          # Докерфайл генератора данных
│   ├── generate_data.py                    # Python-скрипт генерирующий данные
│   └── requirements.txt                    # Зависимости сервиса генератора данных
│
└── db/                         # Сервисы баз данных проекта
    ├── mongo/                              # Сервис MongoDB
    └── postgres/                           # Сервис PostgeSQL
```  

## Развертывание проекта
1. **Клонируйте репозиторий:**
   ```bash
   git clone https://github.com/SkyRanger2010/DE2025_ETL_PROJECT.git
   cd DE2025_ETL_PROJECT
   ```
2. **Дайте необходимые права на папку с логами airflow:**
   ```bash
   sudo useradd -m -d /home/airflow -s /bin/bash airflow
   sudo groupadd airflow
   sudo usermod -aG airflow airflow
   sudo chown -R airflow:airflow ./airflow/logs
   sudo chmod -R 777 ./airflow/logs
   ```
3. **Запустите Docker-контейнеры:**
   ```bash
   docker-compose up -d
   ```
4. **Откройте Airflow в браузере:**
   ```
   http://localhost:8080
   ```
5. **Запустите DAG'и в Airflow:**
   - Перейдите в интерфейс Apache Airflow.
   - Запустите выполнение необходимых DAG'ов вручную.

## Генератор данных

Генератор данных предназначен для создания тестовых данных в MongoDB. Он используется для наполнения базы случайными значениями, имитируя реальный поток данных.

### Данные, генерируемые скриптом

1. **user_sessions** – информация о сессиях пользователей.
   - `session_id` – уникальный идентификатор сессии.
   - `user_id` – идентификатор пользователя.
   - `start_time` – время начала сессии.
   - `end_time` – время завершения сессии.
   - `pages_visited` – список посещенных страниц.
   - `device` – информация об устройстве пользователя.
   - `actions` – список действий пользователя.

2. **product_price_history** – история изменения цен на товары.
   - `product_id` – идентификатор товара.
   - `price_changes` – список изменений цен (дата и цена).
   - `current_price` – текущая цена товара.
   - `currency` – валюта цены.

3. **event_logs** – логи событий пользователей.
   - `event_id` – уникальный идентификатор события.
   - `timestamp` – временная метка события.
   - `event_type` – тип события (например, вход, выход, ошибка, клик).
   - `details` – дополнительная информация о событии.

4. **support_tickets** – обращения пользователей в поддержку.
   - `ticket_id` – уникальный идентификатор тикета.
   - `user_id` – идентификатор пользователя.
   - `status` – статус тикета (открыт, закрыт, в ожидании).
   - `issue_type` – тип проблемы (ошибка, запрос на новую функцию и т. д.).
   - `messages` – список сообщений в тикете.
   - `created_at` – дата создания тикета.
   - `updated_at` – дата последнего обновления тикета.

5. **user_recommendations** – рекомендации товаров пользователям.
   - `user_id` – идентификатор пользователя.
   - `recommended_products` – список рекомендованных товаров.
   - `last_updated` – время последнего обновления рекомендаций.

6. **moderation_queue** – очередь на модерацию отзывов.
   - `review_id` – идентификатор отзыва.
   - `user_id` – идентификатор пользователя.
   - `product_id` – идентификатор товара.
   - `review_text` – текст отзыва.
   - `rating` – оценка товара.
   - `moderation_status` – статус модерации (на проверке, одобрен, отклонен).
   - `flags` – список флагов (например, жалобы на отзыв).
   - `submitted_at` – дата отправки отзыва.

7. **search_queries** – поисковые запросы пользователей.
   - `query_id` – уникальный идентификатор запроса.
   - `user_id` – идентификатор пользователя.
   - `query_text` – текст запроса.
   - `timestamp` – время выполнения запроса.
   - `filters` – список примененных фильтров.
   - `results_count` – количество результатов запроса.

### Запуск генератора данных
Генератор данных автоматически разворачивается после сервиса MongoDB и заполняет MongoDB тестовыми записями.
По умолчанию, генератор использует параметры из `.env`-файла для определения количества генерируемых записей в каждой коллекции.

## Описание пайплайнов

### Общие сведения

В проекте используются следующие инструменты и подходы для реализации ETL-пайплайнов:
- **Извлечение данных (`extract`)**: Данные извлекаются из MongoDB с использованием библиотеки `pymongo`, обеспечивающей подключение к базе и выполнение запросов.
- **Трансформация данных (`transform`)**: Для обработки данных используются библиотеки `pandas` (для манипуляций с DataFrame, для нормализации данных, удаления дубликатов и преобразования форматов).
- **Загрузка данных (`load`)**: Данные записываются в PostgreSQL с помощью `sqlalchemy` и `pandas.to_sql()`, что позволяет автоматизировать создание таблиц и загрузку данных.
- **Автоматизация процессов**: Управление пайплайнами осуществляется с помощью **Apache Airflow**, где DAG'и выполняют поэтапное выполнение задач в зависимости от установленного расписания.
- **Построение витрин**: Для построения витрин данных используется механизм прямых запросов в БД PostgreSQL с помощью **SQLExecuteQueryOperator** в DAG. Тексты запросов вынесены в отдельные файлы `.sql`
- **Автопайплайны**: Используется **TriggerDagRunOperator** для запуска и контроля завершения необходимых репликаций перед формированием витрины

## 1 Пайплайны репликации данных

Эти пайплайны **извлекают данные из MongoDB**, очищают их и загружают в **PostgreSQL (`source.*`)**.  

| DAG ID                     | Источник данных          | Назначение в PostgreSQL   |
|----------------------------|--------------------------|---------------------------|
| `user_sessions_etl`        | `MongoDB.user_sessions`  | `source.user_sessions`    |
| `event_logs_etl`           | `MongoDB.event_logs`     | `source.event_logs`       |
| `search_queries_etl`       | `MongoDB.search_queries` | `source.search_queries`   |
| `user_recommendations_etl` | `MongoDB.user_recommendations` | `source.user_recommendations` |
| `moderation_queue_etl`     | `MongoDB.moderation_queue` | `source.moderation_queue` |
| `support_tickets_etl`      | `MongoDB.support_tickets` | `source.support_tickets` |
| `product_price_history_etl` | `MongoDB.product_price_history` | `source.product_price_history` |

### Как работает процесс?
1. **Извлечение (`Extract`)**  
   - Данные загружаются из MongoDB с использованием `pymongo`.

2. **Трансформация (`Transform`)**  
   - Очистка данных от дубликатов.
   - Приведение типов (`datetime`, `decimal`, `array` → `SQL-совместимые`).
   - Разбивка вложенных структур (например, `recommended_products`) и нормализация таблиц.

3. **Загрузка (`Load`)**  
   - Создаются индексы для ускорения аналитических запросов.
   - Данные записываются в PostgreSQL (`source.*`).
---
### 2. Пайплайны создания аналитических витрин

#### 2.1 Витрина активности пользователей (`mart.users_activity_mart`)
**Описание:**  
Эта витрина агрегирует данные о пользовательской активности на основе их сессий, поисковых запросов, обращений в поддержку и рекомендаций продуктов.

**Данные в витрине:**
- `user_id` – идентификатор пользователя.
- `total_sessions` – общее количество сессий пользователя.
- `first_session_time` – время начала первой зафиксированной сессии (формат `DD-MM-YYYY HH:MM`).
- `last_session_time` – время окончания последней зафиксированной сессии (формат `DD-MM-YYYY HH:MM`).
- `avg_session_duration_min` – средняя продолжительность сессии в минутах.
- `total_session_duration_min` – общее время всех сессий в минутах.
- `total_search_queries` – количество поисковых запросов пользователя.
- `support_tickets_count` – количество обращений пользователя в поддержку.
- `recommended_products_count` – количество рекомендованных пользователем товаров.

**Источник данных:**
- `source.user_sessions`
- `source.search_queries`
- `source.support_tickets`
- `source.user_recommendations`

---

#### 2.2 Витрина эффективности работы поддержки (`mart.support_efficiency_mart`)
**Описание:**  
Эта витрина агрегирует статистику по обработке обращений пользователей в поддержку, группируя данные по **типу обращения (`issue_type`)** и **дню создания (`created_date`)**.

**Данные в витрине:**
- `created_date` – день создания тикетов (формат `YYYY-MM-DD`).
- `created_month` – месяц создания тикетов (формат `YYYY-MM`).
- `issue_type` – тип обращения в поддержку.
- `total_tickets` – общее количество тикетов данного типа за день.
- `open_tickets` – количество открытых тикетов.
- `pending_tickets` – количество тикетов в процессе обработки.
- `closed_tickets` – количество закрытых тикетов.
- `avg_resolution_time_minutes` – среднее время решения **только для закрытых тикетов** (в минутах).
- `monthly_total_tickets` – общее количество тикетов данного типа за месяц.
- `monthly_open_tickets` – количество открытых тикетов данного типа за месяц.
- `monthly_pending_tickets` – количество тикетов в процессе обработки за месяц.
- `monthly_closed_tickets` – количество закрытых тикетов данного типа за месяц.

**Источник данных:**
- `source.support_tickets`

### 3. Автопайплайны

#### 3.1 Автопайплайн для витрины активности пользователей.
**DAG:** `run_users_activity_pipeline`  

### Как работает?
   1. **Запускает DAG'и репликации данных** (`TriggerDagRunOperator`):
      - `user_sessions_etl`
      - `search_queries_etl`
      - `support_tickets_etl`
      - `user_recommendations_etl`

   2. **Ждет их завершения** (`wait_for_completion`=`True`).
   3. **Запускает DAG `users_activity_mart_create`** для обновления витрины.

#### 3.2 Автопайплайн для витрины эффективности работы поддержки.
**DAG:** `run_support_efficiency_pipeline`  

### Как работает?
   1. **Запускает DAG репликации данных** (`TriggerDagRunOperator`):
      - `support_tickets_etl`

   2. **Ждет его завершения** (`wait_for_completion`=`True`).
   3. **Запускает DAG `support_efficiency_mart_create`** для обновления витрины.

---

## Контакты
Автор: *Василий Сатанцев*  
Email: *vasily.satantsev@gmail.com*  
GitHub: [DE2025_ETL_PROJECT](https://github.com/SkyRanger2010/DE2025_ETL_PROJECT)
